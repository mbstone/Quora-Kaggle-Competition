{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Exploratory Data Analysis\n",
    "Brittany Bennett  \n",
    "11/20/2018  \n",
    "\n",
    "## Competition Description  \n",
    "An existential problem for any major website today is how to handle toxic and divisive content. Quora wants to tackle this problem head-on to keep their platform a place where users can feel safe sharing their knowledge with the world.  \n",
    "\n",
    "Quora is a platform that empowers people to learn from each other. On Quora, people can ask questions and connect with others who contribute unique insights and quality answers. A key challenge is to weed out insincere questions -- those founded upon false premises, or that intend to make a statement rather than look for helpful answers.  \n",
    "\n",
    "In this competition, Kagglers will develop models that identify and flag insincere questions. To date, Quora has employed both machine learning and manual review to address this problem. With your help, they can develop more scalable methods to detect toxic and misleading content.  \n",
    "\n",
    "Here's your chance to combat online trolls at scale. Help Quora uphold their policy of “Be Nice, Be Respectful” and continue to be a place for sharing and growing the world’s knowledge.  \n",
    "\n",
    "## Data Description  \n",
    "In this competition you will be predicting whether a question asked on Quora is sincere or not.  \n",
    "\n",
    "An insincere question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is insincere:  \n",
    "\n",
    "Has a non-neutral tone  \n",
    "-  Has an exaggerated tone to underscore a point about a group of people  \n",
    "-  Is rhetorical and meant to imply a statement about a group of people  \n",
    "-  Is disparaging or inflammatory  \n",
    "Suggests a discriminatory idea against a protected class of people, or seeks confirmation of a stereotype\n",
    "-  Makes disparaging attacks/insults against a specific person or group of people  \n",
    "-  Based on an outlandish premise about a group of people  \n",
    "-  Disparages against a characteristic that is not fixable and not measurable  \n",
    "Isn't grounded in reality\n",
    "-  Based on false information, or contains absurd assumptions  \n",
    "-  Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers  \n",
    "\n",
    "The training data includes the question that was asked, and whether it was identified as insincere (target = 1). The ground-truth labels contain some amount of noise: they are not guaranteed to be perfect.  \n",
    "\n",
    "Note that the distribution of questions in the dataset should not be taken to be representative of the distribution of questions asked on Quora. This is, in part, because of the combination of sampling procedures and sanitization measures that have been applied to the final dataset.  \n",
    "\n",
    "**File descriptions**\n",
    "-  train.csv - the training set\n",
    "-  test.csv - the test set\n",
    "-  sample_submission.csv - A sample submission in the correct format\n",
    "\n",
    "### enbeddings/ - (see below)\n",
    "Data fields  \n",
    "qid - unique question identifier  \n",
    "question_text - Quora question text  \n",
    "target - a question labeled \"insincere\" has a value of 1, otherwise 0  \n",
    "This is a Kernels-only competition. The files in this Data section are downloadable for reference in Stage 1. Stage 2 files will only be available in Kernels and not available for download.  \n",
    "\n",
    "What will be available in the 2nd stage of the competition?  \n",
    "In the second stage of the competition, we will re-run your selected Kernels. The following files will be swapped with new data:  \n",
    "\n",
    "test.csv - This will be swapped with the complete public and private test dataset. This file will have ~56k rows in stage 1 and ~376k rows in stage 2. The public leaderboard data remains the same for both versions. The file name will be the same (both test.csv) to ensure that your code will run.\n",
    "sample_submission.csv - similar to test.csv, this will be changed from ~56k in stage 1 to ~376k rows in stage 2 . The file name will remain the same.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Get This Party Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a Peer\n",
    "We can take a quick look at the data to see what we're working with. We see that \"qid\" corresponds to the unique question identified ('question id'), and the question_text contains a unique string of the question.\n",
    "\n",
    "There are 56,370 separate questions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00014894849d00ba98a9</td>\n",
       "      <td>My voice range is A2-C5. My chest voice goes u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000156468431f09b3cae</td>\n",
       "      <td>How much does a tutor earn in Bangalore?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000227734433360e1aae</td>\n",
       "      <td>What are the best made pocket knives under $20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0005e06fbe3045bd2a92</td>\n",
       "      <td>Why would they add a hypothetical scenario tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00068a0f7f41f50fc399</td>\n",
       "      <td>What is the dresscode for Techmahindra freshers?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  00014894849d00ba98a9  My voice range is A2-C5. My chest voice goes u...\n",
       "1  000156468431f09b3cae           How much does a tutor earn in Bangalore?\n",
       "2  000227734433360e1aae  What are the best made pocket knives under $20...\n",
       "3  0005e06fbe3045bd2a92  Why would they add a hypothetical scenario tha...\n",
       "4  00068a0f7f41f50fc399   What is the dresscode for Techmahindra freshers?"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              56370\n",
       "question_text    56370\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
